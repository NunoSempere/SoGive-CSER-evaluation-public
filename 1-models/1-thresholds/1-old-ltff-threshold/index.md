# The LTFF threshold

Initially, I was thinking in terms of the "x-risk community", and "the marginal LTFF x-risk grant". However, I think this is an unneeded level of indirection, because most LTFF grants are going to AI safety. So, it seems more parsimonious to look at the size of the "AI safety community", it's cummulative impact, and therefore it's impact per capita, and then think about what the marginal LTFF grant 

Factors at play:

- Impact of the (reasonably active) AI safety community, in basis points
  - Total AI xrisk
  - Share of that x-risk that they have reduced
- Size of the AI safety community, in terms of number of FTEs
- Impact of marginal LTFF grants relative to the average (not median) full-time researchers

Note that FTEs could be working in different things, e.g.: technical research, movement building, governance, etc. In an ideal world in which the LTFF was absurdly highly competent, we could make an argument based on the efficient markets hypothesis: marginal grants across these three areas are likely to be equally valuable, because if they weren't, the LTFF could have shifted funding. However, I don't think that's the case, because we are just not dealing with levels of absurdly high competence here.
