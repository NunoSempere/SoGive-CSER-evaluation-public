Lower and upper bound thresholds for existential risk
=====================================================

## Most conservative bounds

### Lower bound

Attained by: Open Philanthropy should be willing to spend all of the money assigned to existential risk to bring existential risk to zero.

- Minimum amount of x-risk funding: $3B
  - Reasoning: Moskovitz has over $10B, but not all of it is assigned to existential risk
- Maximum amount of x-risk: 100%
- Corresponds to:
  - 3B for 100% reduction in x-risk
  - 30M for 1% reduction in x-risk
  - 300k for 0.01% reduction in x-risk

Conclusion: 300K for a 0.01% is a no-brainer; opportunities like that should be immediately taken.

### Upper bound

Attained by: undilluted cost to society given very conservative assumptions. With a discount rate of d, and a steady-state population of N, and a willingness to pay of $X, the total value of the future is N·$X/d, so the willingness to pay for 0.01% of it would be 0.01·N·$X/d

- Steady state population: 10B
- Willingness to pay for a year of life: $100K
- Nature of x-risk: singular event (I'm guessing one should be willing to pay more than to dillute yearly risk)
- Minimum discount rate: 0.5% (technically this could be lower, but 0.5% seems pretty low to me already)
- Discounted value of future: 10B * 100K / 0.5% = 200,000T = 200KT
- Maximum amount of x-risk: 100%
- Corresponds to:
  - 200KT for 100% reduction in x-risk
  - 1000T for 1% reduction in x-risk
  - 10T for 0.01% reduction in x-risk
  - For reference: US GDP is about 20T

Conclusion: Amounts greater than 10T for a 0.01% reduction in x-risk are clearly reduction.

### Commentary on most conservative upper bound

We can bound how much our willingness to pay for a 0.01% reduction in x-risk should be as between 300K and 10T for a 0.01% reduction in existential risk. Because this estimate is so wide, it's not clear that it's clearly better than nothing.

## Early judgmental bound

Some questions that we could try to ask to reduce the upper bound:

- What is a scalable baseline intervention. What is the equivalent of GiveDirectly for existential risk?
- How much *can* humanity spend in the next 10 years?
- Is humanity worth less than 2000 KT?

### Lower bound

Attained by: The existential risk community should spend all its money even if there was only a 10% chance of existential risk. Also, Open Philanthropy isn't the only funder.

- Best-guess on amount of x-risk funding: $7B
  - Reasoning: Dustin Moskovitz isn't the only funder. You also have Jan Tallin ($1B) and a bunch of others.
- How much x-risk in the next few decades: 10% (my best guess)
- Corresponds to:
  - 7B for 10% reduction in x-risk
  - 700M for 1% reduction in x-risk
  - 70M for 0.1% reduction in x-risk
  - 7M for 0.01% reduction in x-risk

### Upper bound

Attained by: Humanity can't really "spend its future". I'm guessing that the most one could allocate to this project could be the equivalent of 10 years of 30M humans. That is, you can't pay 20 kilo-trillions in the previous estimate; where would they even come from.

- Maximum spend: 
  - Initial trial: 10 years of 10B humans accounted for at 100k/year = 10,000 KB = 10KT
  - Progressive lower bound: 10 years of 100M humans accounted for at 100k/year = 10,000 KB = 100,000KM = 100KB
  - Progressive lower bound: 10 years of 30M humans accounted for at 100k/year = 30,000KM = 30KB
- Maximum x-risk: Still 100%. 
- Corresponds to:
  - 30 KB for 100% x-risk
  - 3 KB for 10% x-risk
  - 300B for 1% x-risk
  - 30B for 0.1% x-risk
  - 3B for 0.01% x-risk

### Commentary using more judgmental bounds

7M to 30B for a 0.1% reduction in x-risk is a tighter bound. It is now a useful bound: 7M is going to be in the same order of magnitude as CSER's budget for some period (though not sure if it's going to be for a couple of months or for a couple of years). So if we can somehow ascertain that they reduced existential risk by at least that amount, they could pass our sanity check.

One way to establish that could be:

- What is the minimum amount by which the x-risk summit reduced existential risk?
- What is the minimum share of the x-risk summit which can be attributed to CSER?

If CSER's budget is lower than 7M and its contribution through the x-risk summit is more than 0.01%, it'd be a good deal.

## Baselining against scalable interventions

These are just rough notes:

- Biological risk as the GiveDirectly of existential risk? 
- Some kind of Manhattan project for AI safety?
- ...
